The writing and testing of our mySocket and myServer classes was done in NetBeans 7.3.  The one exception to this was when doing the Lossy Channel testing. The Lossy Channel program was run separately in Eclipse, while the sender and receiver were still run in NetBeans. We chose to develop our classes in NetBeans since the Java classes at WSU are taught with it and we were familiar with it. This did create something of a problem, since NetBeans refused to import the zip project file. We solved this by importing the zip file in to Eclipse and saving as a project. Then we were able to import the Eclipse project in to NetBeans. Since we were only running the Lossy Channel program, it was easier to just run it in Eclipse.      

Our program compiles and displays data to the screen from the Mona Lisa text file. It appears to us to be functioning as it should. The sender program reads and displays the characters of the text file as it is read in.  Also, the characters are displayed properly in the receiver window.  It did this without displaying any of the characters in red, which indicates that we have the Stop and Wait protocol working correctly.  It did however display red characters when we started the sender window before the receiver window. This is because some of the characters sent by the sender were not received by the receiver. This resulted in the receiver acking its received data out of order. 

We tested this program following the instructions called out in the pdf file on writing it. This was done with both programs running on the same computer. First we started the receiver program, and then the sender so that the receiver was ready to receive characters when the sender sent them. The sender sent data to port 9876 on localhost except when testing with the Lossy Channel. The receiver by default listened to port 9876 on localhost. We tested the two communicating directly mostly with data transmission rates of 100ms and 200 ms. With 200ms we didn't have any changed data, while at 100 ms we had some. This showed that the longer it took to transmit the data compared to our timout interval, the greater the chance that some would change. We varied this more when testing with the Lossy Channel proxy.

The Lossy Channel program of course caused the program more problems as it was written to simulate less than ideal data propogation conditions. We ran it following the directions with the sender sending to the Lossy Channel Proxy on port 9875. The receiver was run so it listened for data on port 9876(its default) and localhost. Other parameters that could be changed in the proxy were the packet delay and loss ratio. First we ran it with a packet loss ratio of 0.0 and varied the packet delay from 200 ms down to 1 ms. One thing became immediately clear. Having long delays can result in lost and changed packets. As we decreased the delay, the amount of received packets dramaticaly increased and the amount of changed packets decreased. This was even though all the packet delays were less than our sender packet timout interval of 1000 ms. The sender in all cases was sending at 100 characters/second.  

Next we kept the packet delay constant at 1 ms and varied the loss ratio. We tried it with several loss ratios from 0.0 to 0.25. It didn't take long to see that there are limits to the amount of data that may be sent in a network connection that drops packets. As we increased the loss ratio, the amount of characters received dropped considerably and the amount of changed characters increased.  It was interesting to see from the Lossy Channel statistics that when some packets were dropped, the sender would resend them with the receiver ultimately receiving them. Our protocol did work up to a point.      
